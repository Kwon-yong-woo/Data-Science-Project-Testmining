{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samsung\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air.xlsx', 'air_pro.xlsx', 'buzz.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3개의 데이터 있는 dir 지정하기\n",
    "path_ = r\"C:\\Users\\Samsung\\jupyter\\Project_Deep_learning_2020\\data\\ear_phone\"\n",
    "file_list = os.listdir(path_)\n",
    "file_list_xlsx = [f for f in file_list if f.endswith(\".xlsx\")]\n",
    "file_list_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_list_xlsx:\n",
    "    file_path = path_ + \"\\\\\" + f\n",
    "    name = f.replace(\".xlsx\",\"\")\n",
    "    globals () [\"df_{}\".format(name)] =  pd.read_excel(file_path).drop(columns = \"Unnamed: 0\")\n",
    "    globals () [\"df_{}\".format(name)][\"contents\"] =  globals () [\"df_{}\".format(name)][\"contents\"].map(lambda x : str(x).replace(\"None\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pos tagging\n",
    "\n",
    "- version 2가지 중 twitter 사용 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(df_,version):\n",
    "    pos = []\n",
    "    words = []\n",
    "    for i in tqdm(range(len(df_))):\n",
    "        if version == \"kkma\":\n",
    "            p = kkma.pos(df_[\"contents\"][i])\n",
    "        elif version == \"twitter\":\n",
    "            p = twitter.pos(df_[\"contents\"][i])\n",
    "        word = [w[0] for w in p]\n",
    "        pos.append(p)\n",
    "        words.append(word)\n",
    "    df_[\"tag\"] = pos\n",
    "    df_[\"words\"] = words\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>contents</th>\n",
       "      <th>liked</th>\n",
       "      <th>Cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32215</th>\n",
       "      <td>2020.01.29</td>\n",
       "      <td>허*영</td>\n",
       "      <td>Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2020.01.29\\n저는 삼성 갤럭시 S9+ 쓰는데 친구들이 다 에어팟을 들고 있...</td>\n",
       "      <td>52</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32216</th>\n",
       "      <td>2020.01.29</td>\n",
       "      <td>신*진</td>\n",
       "      <td>Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32217</th>\n",
       "      <td>2020.01.29</td>\n",
       "      <td>유*수</td>\n",
       "      <td>Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>2020.01.29</td>\n",
       "      <td>성*수</td>\n",
       "      <td>Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>아이폰이아니라서 끊겨서들림 업데이트해도 잘안됨</td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32219</th>\n",
       "      <td>2020.01.29</td>\n",
       "      <td>변*주</td>\n",
       "      <td>Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>짱짱</td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    id                                               item  \\\n",
       "32215  2020.01.29  허*영   Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...   \n",
       "32216  2020.01.29  신*진   Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...   \n",
       "32217  2020.01.29  유*수   Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...   \n",
       "32218  2020.01.29  성*수   Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...   \n",
       "32219  2020.01.29  변*주   Apple 에어팟 2세대 유선 충전 모델 (블루투스 5.0), MV7N2KH/A, ...   \n",
       "\n",
       "       score                                           contents  liked Cate  \n",
       "32215      5  2020.01.29\\n저는 삼성 갤럭시 S9+ 쓰는데 친구들이 다 에어팟을 들고 있...     52  air  \n",
       "32216      5                                                         0  air  \n",
       "32217      5                                                         0  air  \n",
       "32218      1                          아이폰이아니라서 끊겨서들림 업데이트해도 잘안됨      0  air  \n",
       "32219      5                                                 짱짱      0  air  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▍                                        | 32196/70146 [01:00<00:49, 772.59it/s]"
     ]
    }
   ],
   "source": [
    "## test 에 자신 data 넣어서 돌리기\n",
    "\n",
    "test = df_air\n",
    "test_pos = pos_tagging(test,\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석에 사용할 품사 선택을 위한 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_counter(df_tag):\n",
    "    tag = []\n",
    "    for i in range(len(df_tag)):\n",
    "        for i in df_tag[\"tag\"][i]:\n",
    "            tag.append(i[1])\n",
    "    return Counter(tag).keys(),Counter(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sear(df,pos):\n",
    "    all_ = []\n",
    "    wo = []\n",
    "    for li in df[\"tag\"]:\n",
    "        for i in li:\n",
    "            if i[1] == pos:\n",
    "                all_.append(i)\n",
    "                wo.append(i[0])\n",
    "    return all_,wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_,counter_ = pos_counter(test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in  tag_:\n",
    "    print(key)\n",
    "    print(Counter((tag_sear(test_pos,key))[1]).most_common(100))\n",
    "    print(\"_\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원하는 품사선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_(df,igs):\n",
    "    list_1 = []\n",
    "    for list_ in df.loc[:,\"tag\"]:\n",
    "        list_2 = []\n",
    "        for i in range(len(list_)):\n",
    "            #print(list_[i])\n",
    "            if list_[i][1] in igs:\n",
    "                list_2.append(list_[i][0])\n",
    "        list_1.append(list_2)\n",
    "    return list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_list = [\"Noun\",\"Adjective\",\"Verb\",\"Adverb\",\"Alpha\"]\n",
    "all_pos = tag_\n",
    "customize = [\"Noun\",\"Adjective\",\"Verb\",\"Adverb\",\"Alpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tag(df_,pos_list,customize,pos_all):\n",
    "    for tag in pos_list:\n",
    "        df_.loc[:,tag] = only_(df_,tag)\n",
    "    df_.loc[:,\"customize\"] = only_(df_,customize)\n",
    "    df_.loc[:,\"all\"] = only_(df_,pos_all)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_split = split_tag(test_pos,po_list,customize,all_pos)\n",
    "test_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = test_split\n",
    "win_size = 5\n",
    "#target_col = \"All\"\n",
    "\n",
    "def word2vec_model(df_all,target_col,win_size):\n",
    "    model_words = Word2Vec(sentences=df_all[target_col], window = win_size, min_count=0,iter=100, sg=1)\n",
    "    return model_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = word2vec_model(test_split,\"all\",5)\n",
    "model_word.most_similar(\"좋아요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = word2vec_model(test_split,\"customize\",5)\n",
    "model_word.most_similar(\"좋아요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 많이 나오는 단어 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_mostdf(df_,target_tag,most_n):\n",
    "    df_most = pd.DataFrame()\n",
    "    word = Counter(df_[target_tag].sum()).most_common(most_n)\n",
    "    df_most[\"word\"] = [n[0] for n in word]\n",
    "    df_most[\"count\"] = [n[1] for n in word]\n",
    "    return df_most\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선택 parameter 상위 몇개 추출?\n",
    "most_n = 800\n",
    "target_tag = \"Noun\"\n",
    "dm = make_mostdf(test_split,target_tag,most_n)\n",
    "dm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나중에 topic modeling를 쓰기 위해서 데이터 추출\n",
    "\n",
    "- 해당 단어가 있는 sentence 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentence(df,target,version):\n",
    "    senten = []\n",
    "    a = df.loc[:,version]\n",
    "    for i in a:\n",
    "        if target in i:\n",
    "            senten.append(i)\n",
    "    return senten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_(df,dm,version):\n",
    "    sen_ = []\n",
    "    for i in dm.loc[:,\"word\"]:\n",
    "        a_ = find_sentence(df,i,version)\n",
    "        sen_.append(a_)\n",
    "    dm[\"sentences\"] = sen_\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_2 = extract_(test_split,dm,\"customize\")\n",
    "dm_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec 결과도 같이\n",
    "- 해당 단어랑 가장 비슷한 단어 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(df_,w2_model):\n",
    "    most_simi = []\n",
    "    for i in df_[\"word\"]:\n",
    "        ms = w2_model.wv.most_similar(i,topn=20)\n",
    "        most_simi.append(ms)\n",
    "    df_[\"word2vec\"] = most_simi\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = most_similar(dm_2,model_word)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling 도 같이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_moding(k,documents):\n",
    "    K=k\n",
    "    random.seed(0)\n",
    "    D = len(documents)\n",
    "    def p_topic_given_document(topic, d, alpha=0.1):\n",
    "        return ((document_topic_counts[d][topic] + alpha) /(document_lengths[d] + K * alpha))\n",
    "\n",
    "    def p_word_given_topic(word, topic, beta=0.1):\n",
    "        return ((topic_word_counts[topic][word] + beta) /(topic_counts[topic] + V * beta))\n",
    "\n",
    "    def topic_weight(d, word, k):\n",
    "        return p_word_given_topic(word, k) * p_topic_given_document(k, d)\n",
    "\n",
    "    def choose_new_topic(d, word):\n",
    "        return sample_from([topic_weight(d, word, k) for k in range(K)])\n",
    "\n",
    "    def sample_from(weights):\n",
    "        total = sum(weights)\n",
    "        rnd = total * random.random()\n",
    "        for i, w in enumerate(weights):\n",
    "            rnd -= w\n",
    "            if rnd <= 0:\n",
    "                return i\n",
    "\n",
    "    document_topics = [[random.randrange(K) for word in document] for document in documents]\n",
    "    document_topic_counts = [Counter() for _ in documents]\n",
    "    topic_word_counts = [Counter() for _ in range(K)]\n",
    "    topic_counts = [0 for _ in range(K)]\n",
    "    document_lengths = list(map(len, documents))\n",
    "    distinct_words = set(word for document in documents for word in document)\n",
    "    V = len(distinct_words)\n",
    "\n",
    "    D = len(documents)\n",
    "    for d in range(D):\n",
    "        for word, topic in zip(documents[d], document_topics[d]):\n",
    "            document_topic_counts[d][topic] += 1\n",
    "            topic_word_counts[topic][word] += 1\n",
    "            topic_counts[topic] += 1\n",
    "\n",
    "\n",
    "    for d in range(D):\n",
    "        for word, topic in zip(documents[d], document_topics[d]):\n",
    "            document_topic_counts[d][topic] += 1\n",
    "            topic_word_counts[topic][word] += 1\n",
    "            topic_counts[topic] += 1\n",
    "    return document_topic_counts, topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling_edit(data_,window):\n",
    "    k = 1\n",
    "    Topic_2 = []\n",
    "    for num_ in data_.index:\n",
    "        list_ = data_.loc[num_,\"sentences\"]\n",
    "        word_ = data_.loc[num_,\"word\"]\n",
    "        try:\n",
    "            removal = [li.remove(word_) for li in list_]\n",
    "        except:\n",
    "            pass\n",
    "        docu_,topic_words = topic_moding(k,list_)\n",
    "        top = topic_words[0].most_common(window)\n",
    "        Topic_2.append(top)\n",
    "    data_[\"Topic\"] = Topic_2\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = topic_modeling_edit(df_m,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic.to_excel(r\"C:\\Users\\Samsung\\jupyter\\Project_Deep_learning_2020\\data\\ear_phone\\most\\air.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
